{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyvino.model.model import Model\n",
    "from pyvino.util.config import TASKS\n",
    "from pyvino.util.image import imshow, cam_test, cv2pil\n",
    "from pyvino.detector.detector import DetectorHumanPose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=Pv6Cimz4-WE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_name = os.path.basename(os.getcwd())\n",
    "timestamp = notebook_name.split('_')[1]\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_labels_dir = '../data/labels/'\n",
    "path_process_dir = os.path.join('../data/01_DataProcessing/', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_movie_dir = '../data/movie/fps30_mask/'\n",
    "path_save_dir = os.path.join('../data/02_GetPoints/', timestamp)\n",
    "if not os.path.exists(path_save_dir):\n",
    "    os.makedirs(path_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_labels_name_num = os.path.join(path_labels_dir, 'labels_num.csv')\n",
    "labels_name_num = pd.read_csv(path_labels_name_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names = ['forehand', 'backhand', 'foreslice', 'backslice', 'test']\n",
    "file_names = ['backslice']\n",
    "movie_names = [file_name + '.mp4' for file_name in file_names]\n",
    "points_file_names = [file_name + '.csv' for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name = movie_names[0]\n",
    "path_movie_file = os.path.join(path_movie_dir, movie_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detect_face': 'face-detection-adas-0001',\n",
       " 'emotion_recognition': 'emotions-recognition-retail-0003',\n",
       " 'estimate_headpose': 'head-pose-estimation-adas-0001',\n",
       " 'detect_body': 'person-detection-retail-0013',\n",
       " 'estimate_humanpose': 'human-pose-estimation-0001',\n",
       " 'detect_segmentation': 'instance-segmentation-security-0050'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-15 12:13:22,185 - pyvino.detector.detector - INFO - human-pose-estimation-0001 on Darwin\n",
      "2019-09-15 12:13:22,186 - pyvino.detector.detector - INFO - The path to cpu_extension is /opt/intel/openvino/inference_engine/lib/intel64/libcpu_extension.dylib\n",
      "2019-09-15 12:13:22,512 - pyvino.detector.detector - INFO - person-detection-retail-0013 on Darwin\n",
      "2019-09-15 12:13:22,512 - pyvino.detector.detector - INFO - The path to cpu_extension is /opt/intel/openvino/inference_engine/lib/intel64/libcpu_extension.dylib\n"
     ]
    }
   ],
   "source": [
    "det_h = DetectorHumanPose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(det_h.POSE_PARTS_FLATTEN) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nose',\n",
       " 'Neck',\n",
       " 'RShoulder',\n",
       " 'RElbow',\n",
       " 'RWrist',\n",
       " 'LShoulder',\n",
       " 'LElbow',\n",
       " 'LWrist',\n",
       " 'RHip',\n",
       " 'RKnee',\n",
       " 'RAnkle',\n",
       " 'LHip',\n",
       " 'LKnee',\n",
       " 'LAnkle',\n",
       " 'REye',\n",
       " 'LEye',\n",
       " 'REar',\n",
       " 'LEar']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_parts_list = list(det_h.BODY_PARTS.keys())\n",
    "body_parts_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(path_movie_file)\n",
    "\n",
    "# 幅\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# 高さ\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# 総フレーム数\n",
    "count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# fps\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas_org = np.zeros((height, width, 3), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bbox_margin (xmin, ymin, xmax, ymax, bbox_margin):\n",
    "    xmin = int(xmin * (1 - bbox_margin))\n",
    "    ymin = int(ymin * (1 - bbox_margin))\n",
    "    xmax = int(xmax * (1 + bbox_margin))\n",
    "    ymax = int(ymax * (1 + bbox_margin))\n",
    "    return xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_flattens = np.empty((36, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movie = movies[0]\n",
    "path_movie_file = os.path.join(path_movie_dir, movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.zeros([1,len(det_h.POSE_PARTS_FLATTEN)])\n",
    "mat[:,:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backslice.mp4\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    }
   ],
   "source": [
    "for movie in movie_names:\n",
    "    print(movie)\n",
    "    movie_name = os.path.splitext(movie)[0]\n",
    "    path_movie_file = os.path.join(path_movie_dir, movie)\n",
    "    path_save_points = os.path.join(path_save_dir, movie_name + '.csv')\n",
    "    \n",
    "    cap = cv2.VideoCapture(path_movie_file)\n",
    "    frame_num = 0\n",
    "    points_flattens = np.empty((0, 36))\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_num % 100 == 0:\n",
    "            print(frame_num)\n",
    "\n",
    "        frame = np.array(frame)\n",
    "\n",
    "        ############################\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        results = det_h.compute(frame, pred_flag=True, normalize_flag=True)\n",
    "\n",
    "        if len(results['preds']) == 0:\n",
    "            points_flattens = np.vstack([points_flattens, mat])\n",
    "            frame_num += 1\n",
    "            continue\n",
    "\n",
    "        area = 0\n",
    "        for key, values in results['preds'].items():\n",
    "            xmin, ymin, xmax, ymax = values['bbox']\n",
    "            area_new = (ymax - ymin) * (xmax - xmin)\n",
    "            if area_new > area:\n",
    "                area = area_new\n",
    "                largest_num = key\n",
    "\n",
    "        points = results['preds'][largest_num]['norm_points']\n",
    "\n",
    "        ######\n",
    "        points_flatten = points.flatten()\n",
    "        points_flattens = np.vstack([points_flattens, points_flatten])\n",
    "        ######\n",
    "        frame_num += 1\n",
    "        if show:\n",
    "            cv2.imshow('demo', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    points_df = pd.DataFrame(points_flattens, columns=det_h.POSE_PARTS_FLATTEN)\n",
    "    points_df.to_csv(path_save_points, index=False)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_actrec)",
   "language": "python",
   "name": "conda_actrec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
