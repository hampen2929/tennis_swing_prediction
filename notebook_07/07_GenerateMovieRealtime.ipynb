{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuya/anaconda3/envs/actrec/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "from pyvino.detector import DetectorHumanPose, DetectorBody\n",
    "from actrec.util import moving_average, flatten_data, generate_col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_files = ['forehand.MOV', 'backhand.MOV', 'foreslice.MOV', 'backslice.MOV', 'test.MOV']\n",
    "# movie_files = ['backslice.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_movie_dir = '../data/movie/fps30_mask/'\n",
    "path_movie_test_file = '../data/movie/fps30_mask/backslice.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_name = os.path.basename(os.getcwd())\n",
    "timestamp = notebook_name.split('_')[1]\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_generated_movie_dir = os.path.join('../data/07_GenerateMovie/', timestamp)\n",
    "if not os.path.exists(path_generated_movie_dir):\n",
    "    os.makedirs(path_generated_movie_dir)\n",
    "path_save_file = os.path.join(path_generated_movie_dir, 'test_pred.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_label_name_file = '../data/labels/labels_num.csv'\n",
    "path_action_dir = os.path.join('../data/01_DataProcessing/', timestamp)\n",
    "path_point_dir = os.path.join('../data/02_GetPoints/', timestamp)\n",
    "path_split_dir = os.path.join('../data/04_Split/', timestamp)\n",
    "path_test_file_dir = os.path.join(path_split_dir, 'test')\n",
    "path_model_dir = os.path.join('../data/05_train/', timestamp)\n",
    "path_model_file = os.path.join(path_model_dir, 'model.pkl')\n",
    "path_pred_dir = os.path.join('../data/06_Evaluation/', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['forehand', 'backhand', 'foreslice', 'backslice', 'test']\n",
    "# file_names = ['backslice']\n",
    "movie_names = [file_name + '.mp4' for file_name in file_names]\n",
    "points_file_names = [file_name + '.csv' for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_rev_dict = pd.read_csv(path_label_name_file).to_dict()['action_gt_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'idle', 1: 'forehand', 2: 'backhand', 3: 'foreslice', 4: 'backslice'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_rev_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-16 14:20:26,506 - pyvino.detector.detector - INFO - person-detection-retail-0013 on Darwin\n",
      "2019-09-16 14:20:26,507 - pyvino.detector.detector - INFO - The path to cpu_extension is /opt/intel/openvino/inference_engine/lib/intel64/libcpu_extension.dylib\n",
      "2019-09-16 14:20:26,937 - pyvino.detector.detector - INFO - human-pose-estimation-0001 on Darwin\n",
      "2019-09-16 14:20:26,938 - pyvino.detector.detector - INFO - The path to cpu_extension is /opt/intel/openvino/inference_engine/lib/intel64/libcpu_extension.dylib\n",
      "2019-09-16 14:20:27,204 - pyvino.detector.detector - INFO - person-detection-retail-0013 on Darwin\n",
      "2019-09-16 14:20:27,205 - pyvino.detector.detector - INFO - The path to cpu_extension is /opt/intel/openvino/inference_engine/lib/intel64/libcpu_extension.dylib\n"
     ]
    }
   ],
   "source": [
    "det_b = DetectorBody()\n",
    "det_h = DetectorHumanPose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['RShoulder_x', 'RShoulder_y', 'RElbow_x', 'RElbow_y', 'RWrist_x', 'RWrist_y', \n",
    "                         'LShoulder_x', 'LShoulder_y', 'LElbow_x', 'LElbow_y', 'LWrist_x', 'LWrist_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/05_train/07/model.pkl'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = pickle.load(open(path_model_file, \"rb\"))\n",
    "path_model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name_list = gbm.feature_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.zeros(len(target_columns))\n",
    "mat[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/movie/fps30_mask/forehand.mp4'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 0\n",
    "file_name = file_names[num]\n",
    "movie_name = movie_names[num]\n",
    "path_movie_test_file = os.path.join(path_movie_dir, movie_name)\n",
    "path_movie_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/04_Split/07/test/forehand.csv'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_test_file = os.path.join(path_split_dir, 'test', file_name + '.csv')\n",
    "path_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = 'action_gt_num'\n",
    "index_col = 'frame_num'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/04_Split/07/test/forehand.csv'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(path_test_file, index_col=index_col).head()\n",
    "frame_num = min(test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- frame\n",
    "- pred norm pose and generate frame\n",
    "- preproce\n",
    "- pred action\n",
    "- draw result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(path_movie_test_file)\n",
    "# 幅\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# 高さ\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# 総フレーム数\n",
    "count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# fps\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "canvas_org = np.zeros((height, width, 3), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for feature_name in feature_name_list:\n",
    "    feature = feature_name.split('_')[0]\n",
    "    features.append(feature)\n",
    "features = list(np.unique(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/04_Split/07/test/forehand.csv'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4044"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(path_test_file, index_col=index_col).head()\n",
    "frame_num = min(test_df.index)\n",
    "frame_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target_columns = []\n",
    "for feature in features:\n",
    "    target_columns.append(feature + '_x')\n",
    "    target_columns.append(feature + '_y')\n",
    "features_frame = generate_col_names(target_columns)\n",
    "len(features_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queue(arr, arr_add):\n",
    "    dst = np.vstack([arr, arr_add])\n",
    "    dst = np.delete(dst, obj=0, axis=0)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/movie/fps30_mask/test.mp4'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_movie_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_codes = {'red' : (0,0,255),\n",
    "                           'green' : (0,255,0),\n",
    "                           'blue' : (255, 0,0),\n",
    "                           'orange' : (80,127,255),\n",
    "                           'skyblue' : (222,189,137)}\n",
    "\n",
    "action_color = {'idle': 'green', 'forehand': 'red', 'backhand': 'blue', 'foreslice': 'orange', 'backslice': 'skyblue'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_file_name = '{}.mp4'.format(file_name)\n",
    "path_save_movie = os.path.join(path_generated_movie_dir, movie_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/07_GenerateMovie/07/test.mp4'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_save_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/movie/fps30_mask/test.mp4'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_movie_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/movie/fps30_mask/test.mp4'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_movie_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuya/anaconda3/envs/actrec/lib/python3.6/site-packages/pyvino-0.0.1-py3.6.egg/pyvino/detector/detector.py:533: RuntimeWarning: invalid value encountered in greater\n",
      "/Users/yuya/anaconda3/envs/actrec/lib/python3.6/site-packages/pyvino-0.0.1-py3.6.egg/pyvino/detector/detector.py:535: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n"
     ]
    }
   ],
   "source": [
    "show=False\n",
    "width_movie = 1280\n",
    "height_movie = 720\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"H264\")\n",
    "video = cv2.VideoWriter(path_save_movie, fourcc, fps, (width_movie, height_movie))\n",
    "\n",
    "# checker_df  = pd.DataFrame([], columns=feature_actions_df.columns)\n",
    "\n",
    "# test_df = pd.read_csv(path_test_file, index_col=index_col).head()\n",
    "# frame_num = min(test_df.index)\n",
    "frame_num = 0\n",
    "\n",
    "window = 12\n",
    "min_periods = 1\n",
    "\n",
    "canvas_org = np.zeros((height, width, 3), np.uint8)\n",
    "\n",
    "cap = cv2.VideoCapture(path_movie_test_file)\n",
    "\n",
    "points_multi = np.empty((18, 2))\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "points_flattens = np.zeros([30,len(target_columns)])\n",
    "points_flattens[:,:] = np.nan\n",
    "\n",
    "poss = np.empty((0, 4))\n",
    "\n",
    "pred = False\n",
    "\n",
    "a = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if frame_num % 100 == 0:\n",
    "        print(frame_num)\n",
    "    \n",
    "    frame = np.array(frame)\n",
    "    # frame = cv2.resize(frame, (width_movie, height_movie))\n",
    "\n",
    "    ############################\n",
    "    results = det_h.compute(frame, frame_flag=True, pred_flag=True, normalize_flag=True)\n",
    "    frame = results['frame']\n",
    "    ############################\n",
    "\n",
    "    if len(results['preds']) == 0:\n",
    "        points_flattens = np.vstack([points_flattens, mat])\n",
    "        frame_num += 1\n",
    "        video.write(frame)\n",
    "        pred = False\n",
    "        continue\n",
    "\n",
    "    ############################\n",
    "    points_dets = results['preds']\n",
    "    new_area = 0\n",
    "    largets_bbox_num = 0\n",
    "    for num_det, points_det in points_dets.items():\n",
    "        xmin, ymin, xmax, ymax = points_det['bbox']\n",
    "        area = (ymax - ymin) * (xmax - xmin)\n",
    "        if area > new_area:\n",
    "            new_area = area\n",
    "            largets_bbox_num = num_det\n",
    "    ############################\n",
    "    \n",
    "    points = results['preds'][largets_bbox_num]['norm_points']\n",
    "    points = pd.DataFrame(points, index=det_h.BODY_PARTS, columns=['x', 'y'])\n",
    "    points = points.loc[features]\n",
    "    \n",
    "    point_cols = []\n",
    "    for point in points.index:\n",
    "        point_col = [point + '_x', point + '_y']\n",
    "        point_cols.extend(point_col)\n",
    "    \n",
    "    points_flatten = points.values.flatten()\n",
    "    points_flattens = queue(points_flattens, points_flatten)\n",
    "    points_df = pd.DataFrame(points_flattens, columns=point_cols)\n",
    "    # points_df = points_df.loc[:, target_columns]\n",
    "    #  flatten\n",
    "        \n",
    "    ######\n",
    "    # moving_average\n",
    "    \n",
    "    # frames to one columns\n",
    "    #data_df = points_df.values.flatten()\n",
    "    \n",
    "    feature_actions_df = flatten_data(points_df)\n",
    "    # sort features for model　input\n",
    "    feature_actions_df = feature_actions_df.loc[:, feature_name_list]\n",
    "    \n",
    "    #checker_df = pd.concat([checker_df, feature_actions_df], axis=0)\n",
    "    \n",
    "    #  print(feature_actions_df)\n",
    "    y_pred = gbm.predict(feature_actions_df, num_iteration=gbm.best_iteration)\n",
    "    y_pred = np.argmax(y_pred, axis=1)[0]\n",
    "    action_pred = objective_rev_dict[y_pred]\n",
    "    pred = True\n",
    "\n",
    "    ######    \n",
    "    \n",
    "    frame_num += 1\n",
    "            \n",
    "    cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "    if pred:\n",
    "        action_color_code = color_codes[action_color[action_pred]]\n",
    "        cv2.putText(frame, 'pred: ' + action_pred,\n",
    "                                (int(xmax), int(ymin - 10)),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,0,0), 3, cv2.LINE_AA)\n",
    "    \n",
    "        cv2.putText(frame, 'pred: ' + action_pred,\n",
    "                                    (int(xmax), int(ymin - 10)),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, action_color_code, 2, cv2.LINE_AA)\n",
    "\n",
    "    video.write(frame)\n",
    "    if show:\n",
    "        cv2.imshow('demo', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_actrec)",
   "language": "python",
   "name": "conda_actrec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
